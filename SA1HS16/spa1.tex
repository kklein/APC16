%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Programming/Coding Assignment
% LaTeX Template
%
% Original author:
% Ted Pavlic (http://www.tedpavlic.com)
%
%
% This template uses a Perl script as an example snippet of code, most other
% languages are also usable. Configure them in the "CODE INCLUSION 
% CONFIGURATION" section.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage[german]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage[usenames,dvipsnames]{color} % Required for custom colors
\usepackage{graphicx} % Required to insert images
\usepackage{listings} % Required for insertion of code
\usepackage{courier} % Required for the courier font
\usepackage{enumerate} % used for enumerate args
\usepackage{multicol} % columns

\usepackage{pgf} 
\usepackage{tikz}
%\usepackage{forest} % treees :D
%\usetikzlibrary{arrows,automata} %for FSM

% Custom commands
\DeclareMathOperator{\Kl}{Kl} %Klassen von ZustÃÂÃÂ¤nden

\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
% Shamelessly copied from http://tex.stackexchange.com/questions/43008/absolute-value-symbols
\DeclarePairedDelimiter\abs{\lvert}{\rvert} % nice |x|
\DeclarePairedDelimiter\norm{\lVert}{\rVert} % nice ||x||
% Swap the definition of \abs* and \norm*, so that \abs
% and \norm resizes the size of the brackets, and the 
% starred version does not.
\makeatletter
\let\oldabs\abs
\def\abs{\@ifstar{\oldabs}{\oldabs*}}
\let\oldnorm\norm
\def\norm{\@ifstar{\oldnorm}{\oldnorm*}}
\makeatother


% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{\hmwkAuthorName} % Top left header
%\chead{\hmwkClass\ (\hmwkClassInstructor\): \hmwkTitle} % Top center head
%\rhead{\firstxmark} % Top right header
\rhead{}
\lfoot{\lastxmark} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{page\ \thepage\ of\ \protect\pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs

%----------------------------------------------------------------------------------------
%	CODE INCLUSION CONFIGURATION
%----------------------------------------------------------------------------------------

%\definecolor{MyDarkGreen}{rgb}{0.0,0.4,0.0} % This is the color used for comments
%\lstloadlanguages{Pascal} % Load Pascal syntax for listings, for a list of other languages supported see: ftp://ftp.tex.ac.uk/tex-archive/macros/latex/%contrib/listings/listings.pdf
%\lstset{language=Perl, % Use Pascal in this example
%        frame=single, % Single frame around code
%        basicstyle=\small\ttfamily, % Use small true type font
%        keywordstyle=[1]\color{Blue}\bf, % Pascal functions bold and blue
%        keywordstyle=[2]\color{Purple}, % Pascal function arguments purple
%        keywordstyle=[3]\color{Blue}\underbar, % Custom functions underlined and blue
%        identifierstyle=, % Nothing special about identifiers                                         
%        commentstyle=\usefont{T1}{pcr}{m}{sl}\color{MyDarkGreen}\small, % Comments small dark green courier font
%        stringstyle=\color{Purple}, % Strings are purple
%        showstringspaces=false, % Don't put marks in string spaces
%        tabsize=5, % 5 spaces per tab
%        %
%        % Put standard Pascal functions not included in the default language here
%        morekeywords={rand},
%        %
%        % Put Pascal function parameters here
%        morekeywords=[2]{on, off, interp},
%        %
%        % Put user defined functions here
%        morekeywords=[3]{test},
%        %
%        morecomment=[l][\color{Blue}]{...}, % Line continuation (...) like blue comment
%        numbers=left, % Line numbers on left
%        firstnumber=1, % Line numbers start with line 1
%        numberstyle=\tiny\color{Blue}, % Line numbers are blue and small
%        stepnumber=5 % Line numbers go in steps of 5
%}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Java,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

% Creates a new command to include a perl script, the first parameter is the filename of the script (without .p), the second parameter is the caption
\newcommand{\pascalscript}[2]{
\begin{itemize}
\item[]\lstinputlisting[caption=#2,label=#1]{#1.p}
\end{itemize}
}

%----------------------------------------------------------------------------------------
%	DOCUMENT STRUCTURE COMMANDS
%	Skip this unless you know what you're doing
%----------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
%\newcommand{\enterProblemHeader}[1]{
%\nobreak\extramarks{#1}{#1 continued on next page\ldots}\nobreak
%\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
%}

% Header and footer for when a page split occurs between problem environments
%\newcommand{\exitProblemHeader}[1]{
%\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
%\nobreak\extramarks{#1}{}\nobreak
%}

\setcounter{secnumdepth}{0} % Removes default section numbers
\newcounter{homeworkProblemCounter} % Creates a counter to keep track of the number of problems

\newcommand{\homeworkProblemName}{}
\newenvironment{homeworkProblem}[1][Exercise \arabic{homeworkProblemCounter}]{ % Makes a new environment called homeworkProblem which takes 1 argument (custom name) but the default is "Problem #"
\stepcounter{homeworkProblemCounter} % Increase counter for number of problems
\renewcommand{\homeworkProblemName}{#1} % Assign \homeworkProblemName the name of the problem
\section{\homeworkProblemName} % Make a section in the document with the custom problem count
%\enterProblemHeader{\homeworkProblemName} % Header and footer within the environment
}{
%\exitProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
\noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

\newcommand{\homeworkSectionName}{}
\newenvironment{homeworkSection}[1]{ % New environment for sections within homework problems, takes 1 argument - the name of the section
\renewcommand{\homeworkSectionName}{#1} % Assign \homeworkSectionName to the name of the section from the environment argument
\subsection{\homeworkSectionName} % Make a subsection with the custom name of the subsection
%\enterProblemHeader{\homeworkProblemName\ [\homeworkSectionName]} % Header and footer within the environment
}{
%\enterProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

%----------------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%----------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Special Assignment 1} % Assignment title
\newcommand{\hmwkDueDate}{25\ October\ 2015} % Due date
\newcommand{\hmwkClass}{Algorithms, Probability and Computing} % Course/class
\newcommand{\hmwkClassInstructor}{} % Teacher/lecturer
\newcommand{\hmwkAuthorName}{Kevin Klein} % Your name

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title{
\vspace{2in}
\textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
\normalsize\vspace{0.1in}\small{Due\ \hmwkDueDate}\\
\vspace{0.1in}\large{\textit{\hmwkClassInstructor}
\vspace{3in}
}}
\author{\textbf{\hmwkAuthorName}}
\date{} % Insert date here if you want it to appear below your name

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

%\setcounter{tocdepth}{1} % Uncomment this line if you don't want subsections listed in the ToC

\addtocounter{homeworkProblemCounter}{0}
\newpage
%\tableofcontents
%\newpage

%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}
For this exercise, we assume that the relevant random binary search tree holds the set of elements $S$ of size $n$. Without loss of generality, we will assume that $S = \{1, n\}$ and in particular $i \in S \Rightarrow rank(i) = i$.
Let's us the following recursive notation to express the structure of a binary search tree: $ (node)(leftSubtree)(rightSubtree)$.
\begin{enumerate}[a)]
\item

By direct application of definitions: \\
\( \mathbb{E}[Z_2^{(1)}] = \frac{1}{2} \cdot \mathbb{E}[Z_2^{(1)} | root = 1] + \frac{1}{2} \cdot \mathbb{E}[Z_2^{(1)} | root = 2] = \frac{1}{2} + \frac{1}{2} = 1 \\\)
\( \mathbb{E}[Z_2] = \mathbb{E} [\frac{1}{2-1} \cdot \sum_{i=1}^{2-1}(Z_2^{(i)})] = \mathbb{E}[Z_2^{1}] = 1\) \\

\begin{align}
\mathbb{E}[Z_3^{(1)}] 
 & = \frac{1}{6} \cdot \mathbb{E}[Z_3^{(1)} | (1)(2)(3)] + \frac{1}{6} \cdot \mathbb{E}[Z_3^{(1)} | (1)(3)(2)] + \frac{1}{3} \cdot \mathbb{E}[Z_3^{(1)} | (2)(1)(3) ]  \\
 & + \frac{1}{6} \cdot \mathbb{E}[Z_3^{(1)} | (3)(1)(2)] + \frac{1}{6} \cdot \mathbb{E}[Z_3^{(1)} | (3)(2)(1)] \\
 & = \frac{1}{2} \cdot (1 + 2 + 2 + 1 + 1)  = \frac{7}{6}
\end{align}
\begin{align}
\mathbb{E}[Z_3] &= \mathbb{E} [\frac{1}{3-1} \cdot \sum_{i=1}^{3-1}Z_3^{(i)}] = \frac{1}{2} \cdot \mathbb{E}[Z_3^{(1)}] + \frac{1}{2} \cdot \mathbb{E}[Z_3^{(2)}] \\
				&= \frac{1}{2} \cdot (\frac{7}{6} + \frac{1}{6} \cdot \mathbb{E}[Z_3^{(2)} | (1)(2)(3)] + \frac{1}{6} \cdot \mathbb{E}[Z_3^{(2)} | (1)(3)(2)] + \frac{1}{3} \cdot \mathbb{E}[Z_3^{(2)} | (2)(1)(3) ] \\
				&+ \frac{1}{6} \cdot \mathbb{E}[Z_3^{(2)} | (3)(1)(2)] + \frac{1}{6} \cdot \mathbb{E}[Z_3^{(1)} | (3)(2)(1)]) \\
				&= \frac{1}{2} \cdot (\frac{7}{6} + \frac{7}{6}) \\
				&= \frac{7}{6}
\end{align}
\item
\item
\item
\end{enumerate}

[0] APC script, Chapter 2.1 Point/Line Relative to a Convex Polygon, paragraph 'Inside/On/Outside a Cnvex Polygon', p. 39  
[1] APC script, Chapter 2.1 Point/Line Relative to a Convex Polygon, paragraph 'A Line Hitting a Convex Polygon', p. 40  
[2] APC script, Chapter 2.3 Planar Point Location - More exmaples, paragrahp 'Closest Point in the Plane - the Post offce Problem', p.55
\end{homeworkProblem}
%----------------------------------------------------------------------------------------
%	PROBLEM 2
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}

\begin{enumerate}[a)]
\item % 2 a)
	Analogously to the proof of Lemma 1.5 [0], we will proceed with an exhaustive case distinction in order to prove that
	\[ \mathbb{E}[A_i^j] = \frac{p(j)}{\sum_{l=min \{i,j\}}^{max\{i,j\}}p(l)}\]
	\begin{enumerate}[(i)]

	\item $i = j$
		\begin{align}
			\mathbb{E}[A_i^{(j)}] &= {E}[A_j^{(j)}] \\
			&= 1 \text{ (definition of ancestor indicator variable)} \\
			&= \frac{p(j)}{p(j)} \text{ ($p(j) > 0$  is given)} \\
			&= \frac{p(j)}{\sum_{l=min\{i,j\}}^{max\{i,j\}} p(l)} \text{ (as $i=j$)} \\
		\end{align}

	\item $i = 1$ and $j = n$ \\
		Note that $i$ and $j$ will always end up in different subtrees of the root, except for the cases in which either of both is the root. Hence, if none of them is the root, the indicator variable is equal to 0. If $i$ is the root, $j$ is a child of $i$ and $j$ is different from $i$ because $n \geq 2$. Therefore $j$ cannot be an ancestor of $i$ if $i$ is the root. Consequently, the only case is which $j$ is an ancestor of $i$ is when $j$ is the root of the tree. 
		\begin{align}
			\mathbb{E}[A_i^{(j)}] &= \Pr(root=j) \\
			&= \frac{p(j)}{\sum_{l=1}^{n} p(l)} \text{ (definition of the weighted binary tree)} \\
			&= \frac{p(j)}{\sum_{l=min\{i,j\}}^{max\{i,j\}} p(l)}  \text{ (as $i=1$ and $j=n$)} \\
		\end{align}

	\item $j=1$ and $i=n$ \\
		This case is symmetric to case (ii).	

	\item $i \neq j$ and $n > j-i+1$ and $root \in \{min\{i,j\},max\{i,j\}\}$ \\
		If $i$ is the root, $j$ cannot be an ancestor of as we know that $i \neq j$. If $root \in \{min\{i,j\}+1,max\{i,j\}-1\}$, we know that i and j will always end up in different subtrees of the root. Hence, if none of them is the root, the indicator variable is equal to 0.  Consequently, the only case is which $j$ is an ancestor of $i$ is when $j$ is the root of the tree. 
		\begin{align}
			\mathbb{E}[A_i^{(j)}] &= \Pr(root=j| root  \in \{min\{i,j\},max\{i,j\}\} ) \\
			&= \frac{\Pr(root=j)}{\Pr(root  \in \{min\{i,j\},max\{i,j\}\} )}  \text{ (definition of conditional probability)} \\
			&= \frac{\frac{p(j)}{\sum_{l=1}^{n} p(l)}}{ \frac{\sum_{l=min\{i,j\}}^{max\{i,j\}}p(l)}{\sum_{l=1}^{n} p(l)}}   \text{ (definition of the weighted binary tree)} \\
			&= \frac{p(j)}{\sum_{l=min\{i,j\}}^{max\{i,j\}}p(l)}
		\end{align}

	\item $n > j-i+1$ and $root \notin \{min\{i,j\},max\{i,j\}\} $ \\
		As the root must either be smaller than $i$ and smaller than $j$ or larger than $i$ and larger than $j$, we know that $i$ and $j$ will always end up in the same subtree of the root. Note that within the left subtree the ranks of the keys will remain the same. Within the right subtree, the ranks are all decreased by $k$ where $k=root$. Hence the difference of ranks between $i$ and $j$ remains the same in both subtrees. \\
		Therefore, we can now look at the respective subtree containing $i$ and $j$ in an isolated fashion, as we know that the current root does not contribute anything to the notion we look at. In the base case in which $n=2$, we can either apply (i) if $i$ and $j$ are equal and (ii) if they're not. For $n>2$, we can inductively apply cases (i), (ii), (iii), (iv) and (v).
	\end{enumerate}

\item % 2 b) 
	We want to prove that \\
	\[ \forall x,y \in \mathbb{R} \ s.t.\  0 \leq x < y: \frac{x}{y} \leq ln(y) - ln(y-x)\]
	As we know that $x < y$, we can formulate the following
	\[ \exists \  \delta \in \mathbb{R} \ s.t. \ \delta>0 \ and \  x=y-\delta \]
	We know that INSERT NAME HERE \(\forall x \in \mathbb{R}: 1+x \leq e^x \). With $z = ln(\frac{\delta}{y})$ we get the following:
	\begin{align}
		& 1 + ln(\frac{\delta}{y}) \leq e^{ln(\frac{\delta}{y})} \\
		& \Leftrightarrow 1 - ln(\frac{y}{\delta}) \leq \frac{\delta}{y} \\
		& \Leftrightarrow 1 - \frac{\delta}{y} \leq ln(\frac{y}{\delta}) \\
		& \Leftrightarrow \frac{y-\delta}{y} \leq ln(\frac{y}{y-y+\delta}) \\
		& \Leftrightarrow \frac{x}{y} \leq ln(\frac{y}{y - x - \delta + \delta}) \\
		& \Leftrightarrow \frac{x}{y} \leq ln(\frac{y}{y - x}) \\
		& \Leftrightarrow \frac{x}{y} \leq ln(y) - ln(y - x) \\
	\end{align}

\item % 2 c)
	We want to prove that 
	\[ \forall i \in [n]: \mathbb{E} [D_n^{(i)}] \leq 2 \cdot ln(\frac{1}{p(i)}) \]
	\[  \mathbb{E} [D_n^{(i)}] = \sum_{j=1}^{n}\mathbb{E}[A_i^j]\]
\end{enumerate}

\end{homeworkProblem}

%----------------------------------------------------------------------------------------
%	PROBLEM 3
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}
\begin{enumerate}[a)]
\item
\item
\item
\item
\item
\end{enumerate}
\begin{enumerate}[(a)]
	\item 			% (a)
		\( a_0 = 7, a_1 = 1 + 2 * a_0 = 15 \\
		\forall n \geq 2: \)
		\begin{align}
		 a_n &= 1 + 2 \cdot \sum_{i=1}^{n} a_{i-1} \\
		 a_{n-1} &= 1 + 2 \cdot \sum_{i=1}^{n} a_{i-1} \\
		\Rightarrow a_n - a_{n-1} &= 1 + 2 \cdot \sum_{i=1}^{n} a_{i-1} - ( 1 + 2 \cdot \sum_{i=1}^{n} a_{i-1} ) = 2 \cdot a_{n-1}\\
		\Rightarrow a_n & = 3 \cdot a_{n-1} \\
		&= \dots \\
 		&= 3 ^ {n-1} \cdot a_1 \\
		&= 3^{n-1} \cdot 15 \\
		\end{align}
	\item 			% (b)
		\( L_n := length\ of\ a\ central\ path\ in\ a\ BST\ of\ size\ n\ nodes\ \\
		l_n := \mathbb{E}(L_n) \\
		l_0 = 0, l_1 = 1, l_2 = 1/2 \cdot 2 + 1/2 \cdot 1 = 3/2\\
		\forall n \geq 3:\)
		\begin {align}
			l_n &= \sum_{i=1}^{n} ( \mathbb{E}[L_n | root = i] \cdot \Pr[root=i] ) \\
			&=  \sum_{i=1}^{n} ( \mathbb{E}[L_n | root = i] \cdot 1/n ) \\
  			&=  1/n \cdot \sum_{i=1}^{n} ( \mathbb{E}[L_n | root = i]) \\
    			&=  1/n \cdot \sum_{i=1}^{n} ( \mathbb{E}[L_{i-1}] +1) \\
 			&=  1 + 1/n \cdot \sum_{i=1}^{n} (l_{i-1}) \\
		\end{align}
		Instead of recurring with two different expectations, one for going left and one for going right, we reduce the problem to always going left. In other words, this problem is equivalent to the expected length of the left spine. The legitimacy of this statement follows from the fact that we assume our binary search tree to be u.a.r. This tells us, that when 'arriving' at a node, we expect equal left and right subtrees, as they are random search trees themselves and the root was u.a.r. as well. In other words the decision which 'direction' we take is irrelevant when considering the expected length of the path.  \\
		Analogously, \( l_{n-1} = 1/n \cdot \sum_{i=1}^{n-1} (l_{i-1}) \).
 		\begin {align}
		  	n \cdot l_n - (n-1) \cdot  l_{n-1} &= n +  \sum_{i=1}^{n} (l_{i-1}) - ((n-1) +  \sum_{i=1}^{n-1} (l_{i-1}) \\
			&= 1 + l_{n-1} \\
			\Rightarrow n \cdot l_n &= 1 + n \cdot l_{n-1} \\
			\Rightarrow l_n &= 1/n +  l_{n-1} \\
			&= 1/n +  1/(n-1) + \dots + l_3 + l_2 \\
 			&= 1/n +  1/(n-1) + \dots + l_3 + 3/2 \\
  			&= 1/n +  1/(n-1) + \dots + l_3 + 1/2 + 1 \\
  			&= H_n \\
 		\end{align}
		We see that this also holds for \(n=2\) and \(n=1\) and therefore: \( \forall n \in \mathbb{N} - \{0\}. \)
	\item  			% (c)
		\( P_0^{(1)} = P_1^{(1)} = P_2^{(1)} = 0, P_3^{(1)} = 1/3, P_4^{(1)} = 1/4 \cdot 1/3 = 1/12 \\ 	
		\forall n \geq 5: \)
		\begin{align}
			P_n^{(1)} &= \sum_{i=1}^n (( P_n^{(1)} | root=i) \cdot \Pr[root=i]) \\
			&= \sum_{i=1}^n (( P_n^{(1)} | root=i) \cdot 1/n \\
			&= 1/n \cdot \sum_{i=1}^n (( P_n^{(1)} | root=i)   \\
			&= 1/n \cdot \sum_{i=1}^n P_{i-1}^{(1)}   \\
		\end{align}
		Furthermore, \( P_{n-1}^{(1)} =  1/(n-1) \cdot \sum_{i=1}^{n-1} (( P_{i-1}^{(1)} | root=i) \)
		\begin{align}
			\Rightarrow n \cdot P_n^{(1)} - (n-1) \cdot P_{n-1}^{(1)} &= \sum_{i=1}^n P_{i-1}^{(1)} - ( \sum_{i=1}^{n-1} P_{i-1}^{(1)} ) \\
			&= P_{n-1}^{(1)} \\
			\Rightarrow n \cdot P_n^{(1)} &= n \cdot P_{n-1}^{(1)} \\
			\Rightarrow P_n^{(1)} &=  P_{n-1}^{(1)} \\
			&=  P_{n-2}^{(1)} = \dots =  P_{4}^{(1)} \\
			&= 1/12
		\end{align}
		We see that this also holds for \(n=4\) and therefore: \( \forall n \in \mathbb{N}, n \geq 4. \)
	\item 			% (d)
	$n \geq 5,\ 2 \leq i \leq n-3$  \\
	As $i+1$ and $i+2$ are the only descendants of $i$, we have to make sure, that no other keys can end up children of $i$, $i+1$ and $i+2$. We can achieve this by requiring keys $i-1$ and $i+3$ to appear before $i$ in the permutation of keys. This implies, that they are higher in the three, and therefore reached before $i$, $i+1$ and $i+2$. A key can then only land at $i$ if and only if it is inside the range ${i-1, \dots, i+3}$. As there are no keys in this range apart from the keys we care about, no other key than $i+1$ and $i+2$ can reach $i$. Therfore $i$ will not have any other ancestors if this condition is satisfied. \\
	Moreover, $i+1$ and $i+2$ have to follow $i$ in the permutation for obvious reasons.
	\begin{align}
		\mathbb{E} [X_i] &= \sum x_i \cdot \Pr[X_i = x_i] \\
		&= \Pr[X_i = 1] \\
		&= \Pr[\text{keys }i-1 \text{ and } i+3 \text{ appear before }i,\text{ keys } i+1 \text{ and } i+2 \text{ after } i]\\
	\end{align}
	As we consider u.a.r. trees, we can 'ignore' which and how many keys are between the keys we now care for. \\
	How many permutations lead to an accepted tree? There are 2 accepted relative arrangements among $i-1$ and $i+3$, as it is irrelevant which of both comes first, as long as they preceed $i$. Thusly, $i$ has a fixed relative position, i.e. only one Posible relative position. $i+1$ and $i+2$ also have two Posible arrangements, as their relative position is irrelevant, as long as they follow $i$.
	\[\#AcceptedPermutations = 2 \cdot 1 \cdot 2\ = 4 \]
	The amount of Posible permutations is obviously $5!$. 
	\[ \mathbb{E}[X_i] = \frac{4}{5!} = \frac{1}{30}\]
\end{enumerate}
\end{homeworkProblem}

%----------------------------------------------------------------------------------------
%	PROBLEM 4
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}
	\begin{enumerate}[(a)]
	\item %(a)
		Let $S = \{1,\dots, n \} $ be the set of all keys. Let $\Pr_S$ be the probability distribution on $\mathbb{D}_{S}$. For all $v \in V$, $w(v)$ denotes the number of keys in the subtree rooted at $v$. \\
		We define $\widetilde{w} (v)$ followingly: \\
		\[\widetilde{w} (v) = 
			\begin{cases} 
      		1 & w(v) \leq 2 \\
      		{w(v) \choose 2} & otherwise
   			\end{cases}
		\]
		Let $t \in_{u.a.r.} \mathbb{D}_{S}$. \\
		Accordingly, the probability of a tree with nodes $v \in V$ is the following: \\
		\[ \Pr_S[t] = \prod_{v\in V} \frac{1}{\widetilde{w} (v)} \] \\
		Let's observe the different cases to confirm this hypothesis. \\
		$n = 0:$ \\
		$t = \lambda \Rightarrow \Pr_S [t] = 1$ \\
		$n = 1:$ \\
		$t$ is the tree with a single node and a single key $k \in n$ it its root. $\Rightarrow \Pr_S [t] = 1$ \\
		$n = 2:$ \\
		$t$ is the tree with a single node and the keys $i,j \in n$ it its root. $\Rightarrow \Pr_S [t] = 1$ \\
		$n \geq 3:$ \\
		$t$ has a root with keys $i,j \in n, i < j$. Furthermore, $t$ has up to three subtrees $t_l, t_m, t_r$. 
		\begin{align}
			\Pr_S [t] &= Pr_S [root = \{i,j\}] \cdot \Pr_S [t_l] \cdot \Pr_S [t_m] \cdot \Pr_S [t_r] \\
			&= \frac{1}{{w(v) \choose 2}} \cdot \Pr_S [t_l] \cdot \Pr_S [t_m] \cdot \Pr_S [t_r] \\
			&= \frac{1}{\widetilde{w} (v)} \cdot \Pr_S [t_l] \cdot \Pr_S [t_m] \cdot \Pr_S [t_r] \\
		\end{align}
		Analogously[3], 'we can conclude that the values suggested in the assertion of the observation satisfy the recurrence'. 
		[3] APC script, Chapter 1.1 Definition, Lemma 1.1, p.4.
		\item %(b)
		In order to determine $m_n$ and $M_n$ we have a look at the 'best' and 'worst case' of our tree structure regarding the number of nodes. \\
		\emph{Best case} \\
		Any construction holding two keys in each node is best regarding the use of nodes. If the number of keys happens to be odd, one node holds a single key. This leads immediately to the lower bound:
		\[m_n =  \ceil[\Big]{\frac{n}{2}} \]
		\emph{Proof} \\
		Let's assume this bound is not tight, i.e. it exists a tree of size n keys, containing $< \ceil[\big]{\frac{n}{2}}$ nodes. Hence this tree has at most$ \ceil[\big]{\frac{n}{2}} -1 $ nodes, to which we assign n keys. The pidgeonhole principle tells us that this will lead to at least one node to which 3 keys are assigned. This contradicts the definition of our tree strucutre and is therefore imPosible. \\
		\emph{Worst case} \\
		Assuming $n = 4k+1$. \\
		A tree structure degenerating to a 'chain' is the least advantagous regarding the amount of required nodes per keys. By chain we mean to say that every node has three children, but only one of them contains two keys. Therefore, there are 4 keys per 3 nodes in a 'general' level of the tree. By gerneal we mean to say that first and last level are not to be considered at this stage of the argumentation. This leads to the upper bound:
		\[M_n =  \lfloor {\frac{3n}{4}} \rfloor +1 \]
		\emph{Proof}
		Let's assume this bound is not tight, i.e. it exists a tree of size n keys, containing $> \lfloor{\frac{3n}{4}}\rfloor +1 $ nodes. Hence this tree has at least$ \lfloor {\frac{3n}{4}} \rfloor +2 = 3k + 2$ nodes, to which we assign $n=4k+1$ keys. \\
		The tree cannot grow anymore if not at least one of the nodes of a level, which comprises three nodes, has two keys. This holds because we can can 'count' the root for the last level and we also know that $n =4k+1$. In other words, $(3k+2)\cdot \lfloor \frac{1}{3}\rfloor = k$ nodes must hold $(3k+1)\cdot \lfloor \frac{1}{3} \rfloor \cdot 2 = 2k$ keys.  Followingly, there are $3k+2-k = 2k+2$ nodes and $4k+1-2k= 2k+1$ keys 'left'. Obviously, one node will not have a key, which contradicts our definition of a node. Therefore our assumption was wrong and our bound tight.
	\item %(c)
	Let's determine the probability a u.a.r. permutation of $[n]$ yields a u.a.r. ternary search tree $T_n$ with n keys. Say this tree has keys $i$ and $j$ in its root with $i<j$.  \\
	In order to determine this probability, we look at the ratio of the amount of permutations which yield $T_n$ and the amount of Posible permutations. \\
	\(Pos[T_i] = \# \text{valid permutations of }T_i\)  \\
	\(PPos[T_i^n] = \# \text{valid Posibilities to arrange the keys of }T_i \text{ within $n$ keys}\) \\
	\begin{align}
	Pos[T_n] &= Pos[root = \{i,j\}] \cdot Pos[T_{<i}] \cdot Pos[T_{>i, <j}] \cdot Pos[T_{>j}] \cdot PPos[T_{<i}^{n-2}] \cdot PPos[T_{>i,<j}^{n-i-1}] \cdot PPos[T_{>j}^{n-j}] \\
	&= 2 \cdot Pos[T_{<i}] \cdot Pos[T_{>i, <j}] \cdot Pos[T_{>j}] \cdot {(n-2) \choose (i-1)} \cdot {(n-i-1) \choose (j-i-1)} \cdot {(n-j) \choose (n-j)} \\
	&= 2 \cdot Pos[T_{<i}] \cdot Pos[T_{>i, <j}] \cdot Pos[T_{>j}] \cdot {(n-2) \choose (i-1)} \cdot {(n-i-1) \choose (j-i-1)}\\
	\Pr[T_n] &= \frac{Pos[T_n]}{n!} \\
	\end{align}
	\item %(d)
	Let's prove the inequality for all n by inducing over subtrees.
	
	\emph{Base cases} \\
	\( \mathbb{E}[f(T_0)] = 0, \mathbb{E}[f(T_1)] = 1, \mathbb{E}[f(T_2)] = 1 \) \\
	From $n=1$ we see that $c \geq \frac{1}{3}$. Given this, the inequality clearly holds for the base cases.
	
	\emph{Induction hypothesis} \\
	Assume that for an arbitrary $n \geq 3$:
	\[ \forall k<n: \mathbb{E}[f(T_k)] \leq \frac{2}{3}n + c \]
	\emph{Induction step} \\
	As we consider $n \geq 3$, the root contains two roots $i$ and $j$ with $i<j$. 
	\begin{align}
		\mathbb{E}[f(T_n)] &= \sum_{j=1}^n \sum_{i=1}^{j-1} \mathbb{E}[f(T_n)|root=\{i,j\}] \cdot \Pr[root=\{i,j\}] \\
		&= \Pr[root=\{i,j\}] \cdot \sum_{j=1}^n \sum_{i=1}^{j-1} \mathbb{E}[f(T_{i-1})] + \mathbb{E}[f(T_{j-i-1})] + \mathbb{E}[f(T_{n-j})] + 1 \\
		&= \frac{1}{{n \choose 2}} \cdot \sum_{j=1}^n \sum_{i=1}^{j-1} \mathbb{E}[f(T_{i-1})] + \mathbb{E}[f(T_{j-i-1})] + \mathbb{E}[f(T_{n-j})] + 1 \\
		& \leq \frac{1}{{n \choose 2}} \sum_{j=1}^n \sum_{i=1}^{j-1} (\frac{2}{3}(i-1) + c) + (\frac{2}{3}(j-i-1) + c) + (\frac{2}{3}(n-j) + c) \\
		& \leq \frac{1}{{n \choose 2}} \sum_{j=1}^n \sum_{i=1}^{j-1} \frac{2}{3}i - \frac{2}{3}i + \frac{2}{3}j - \frac{2}{3}j + \frac{2}{3}n -\frac{2}{3} -\frac{2}{3} + 3c \\
		& \leq \frac{1}{{n \choose 2}} \sum_{j=1}^n \sum_{i=1}^{j-1} \frac{2}{3}n -\frac{4}{3} + 3c\\
		& \leq \frac{1}{{n \choose 2}} \frac{n\cdot(n-1)}{2} \cdot (\frac{2}{3}n -\frac{4}{3} + 3c) \\
		& \leq \frac{2}{{n\cdot (n-1)}} \frac{n\cdot(n-1)}{2} \cdot (\frac{2}{3}n -\frac{4}{3} + 3c) \\
		& \leq \frac{2}{3}n -\frac{4}{3} + 3c\\
	\end{align}
	In order to validate the induction, we have to make sure that the initial claim holds, i.e. that the constant term stays the same.
	\[c = - \frac{4}{3} + 3c \Rightarrow c= \frac{2}{3} \]
	It remains to check, whether this is sound with the condition we recoginzed in the base case. It obviously does and therefore the induction holds.
	\item %(e)
	Suppose the assumption of (d) still holds, i.e. $T_n$ is a u.a.r. ternary search tree. No matter what the definition of the search tree looks like, we can assume to that our root keys indicate the direction in which to go depending on the current key. No matter what this mapping looks like, as it is based on the search tree property, we can expect a u.a.r. distribution of keys onto the resepctive subtrees.\\
	This allows us, for instance, to assume that within the sum of all Posible roots, we can expect every subtree to have equal expected properties. \\
	For simplicity, assume that the set of keys is $[n]$. \\
	\(\mathbb{E}[f(T_0)] = 0, \mathbb{E}[f(T_1)] = 1, \mathbb{E}[f(T_2)] = 1 \)  \\
	\( \forall n \leq 3 \):
		\begin{align}
			\mathbb{E}[f(T_n)] &= \sum_{j=1}^n \sum_{i=1}^j \mathbb{E}[f(T_n) | root = \{i,j\}] \cdot \Pr[root=\{i,j\}] \\
			&= \Pr[root=\{i,j\}] \cdot \sum_{j=1}^n \sum_{i=1}^j \mathbb{E}[f(T_n) | root = \{i,j\}] \\
			&= \frac{1}{{n \choose 2}} \cdot \sum_{j=1}^n \sum_{i=1}^j \mathbb{E}[f(T_l)] \cdot \mathbb{E}[f(T_m)] \cdot \mathbb{E}[f(T_r)] \\
			&= \frac{1}{{n \choose 2}} \cdot \sum_{j=1}^n \sum_{i=1}^j \mathbb{E}[f(T_{<i})] \cdot \mathbb{E}[f(T_{>i, <j})] \cdot \mathbb{E}[f(T_{>j})] \\
			&= \frac{1}{{n \choose 2}} \cdot \sum_{j=1}^n \sum_{i=1}^j 3 \cdot \mathbb{E}[f(T_{<i})] \\
			&= \frac{1}{{n \choose 2}} \cdot \sum_{j=1}^n \sum_{i=1}^j 3 \cdot \mathbb{E}[f(T_{i-1})] \\
			\mathbb{E}[f(T_{n-1})] &= \frac{1}{{(n-1) \choose 2}} \cdot \sum_{j=1}^{n-1} \sum_{i=1}^j 3 \cdot \mathbb{E}[f(T_{i-1})] \\
			{{n \choose 2}} \cdot \mathbb{E}[f(T_n)] - {{(n-1) \choose 2}} \cdot \mathbb{E}[f(T_{n-1})] &= \sum_{j=1}^n \sum_{i=1}^j 3 \cdot \mathbb{E}[f(T_{i-1})] -  \sum_{j=1}^{n-1} \sum_{i=1}^j 3 \cdot \mathbb{E}[f(T_{i-1})] \\
			&= 3 \cdot \sum_{i=1}^n \mathbb{E}[f(T_{i-1})] \\
			\Rightarrow \mathbb{E}[f(T_n)] &= \frac{{(n-1) \choose 2} + 1}{{n \choose 2}} \cdot \mathbb{E}[f(T_{n-1})] + \frac{3}{{n \choose 2}} \cdot \sum_{i=1}^{n-1} \mathbb{E}[f(T_{i-1})]\
			&= \frac{{(n-1) \choose 2} + 1}{{n \choose 2}} \cdot \mathbb{E}[f(T_{n-1})] + \frac{3}{{n \choose 2}} \cdot \sum_{i=1}^{n-1} \mathbb{E}[f(T_{i-1})]\
		\end{align}
	\end{enumerate}
\end{homeworkProblem}



%----------------------------------------------------------------------------------------
\end{document}
PreferencesEnglish
